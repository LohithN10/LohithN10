{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c74af30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 16:51:55,392 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark=SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736b5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a809c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d993d429",
   "metadata": {},
   "source": [
    "### Create a data frame will all files across all folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a34c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating schema\n",
    "myschema=StructType([StructField(\"DTime\",StringType(),True),\n",
    "                     StructField(\"Electricity_Facility_kW_Hourly\",FloatType(),True),\n",
    "                     StructField(\"Fans_Electricity_kW_Hourly\",FloatType(),True),\n",
    "                     StructField(\"Cooling_Electricity_kW_Hourly\",FloatType(),True),\n",
    "                     StructField(\"Heating_Electricity_kW_Hourly\",FloatType(),True),\n",
    "                     StructField(\"InteriorLights_Electricity_kW_Hourly\",FloatType(),True),\n",
    "                     StructField(\"InteriorEquipments_Electricity_kW_Hourly\",FloatType(),True),\n",
    "                     StructField(\"Gas_Facility_kW_Hourly\",FloatType(),True),\n",
    "                     StructField(\"Heating_Gas_kW_Hourly\",FloatType(),True),\n",
    "                     StructField(\"InteriorEquipments_Gas_kW_Hourly\",FloatType(),True),\n",
    "                     StructField(\"WaterHeater_WaterSystems_Gas_kW_Hourly\",FloatType(),True)\n",
    "                    ])        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997527c",
   "metadata": {},
   "source": [
    "## Loading_data from all folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b8dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.format(\"csv\").option(\"recursiveFileLookup\",\"true\").option(\"header\",\"True\").schema(myschema).load(\"hdfs://127.0.0.1:9000/user/labuser/bdpl/electricity_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c291a",
   "metadata": {},
   "source": [
    "#### Finding the DataFrame shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61bf944d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (1962240, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "col=len(df.columns)\n",
    "rows=df.count()\n",
    "print(f'Dataframe shape:',(rows,col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f469e95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DTime: string (nullable = true)\n",
      " |-- Electricity_Facility_kW_Hourly: float (nullable = true)\n",
      " |-- Fans_Electricity_kW_Hourly: float (nullable = true)\n",
      " |-- Cooling_Electricity_kW_Hourly: float (nullable = true)\n",
      " |-- Heating_Electricity_kW_Hourly: float (nullable = true)\n",
      " |-- InteriorLights_Electricity_kW_Hourly: float (nullable = true)\n",
      " |-- InteriorEquipments_Electricity_kW_Hourly: float (nullable = true)\n",
      " |-- Gas_Facility_kW_Hourly: float (nullable = true)\n",
      " |-- Heating_Gas_kW_Hourly: float (nullable = true)\n",
      " |-- InteriorEquipments_Gas_kW_Hourly: float (nullable = true)\n",
      " |-- WaterHeater_WaterSystems_Gas_kW_Hourly: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2bbf66",
   "metadata": {},
   "source": [
    "### Add a column that contains the filename to this data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955786f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================================>         (164 + 9) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT filename)|\n",
      "+------------------------+\n",
      "|                     224|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newDF=df.withColumn('filename',input_file_name())\n",
    "newDF.show\n",
    "\n",
    "counting=newDF.select(countDistinct('filename'))\n",
    "counting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a20aef",
   "metadata": {},
   "source": [
    "### Find and remove any duplicate rows available in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c19cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DTime: string, Electricity_Facility_kW_Hourly: float, Fans_Electricity_kW_Hourly: float, Cooling_Electricity_kW_Hourly: float, Heating_Electricity_kW_Hourly: float, InteriorLights_Electricity_kW_Hourly: float, InteriorEquipments_Electricity_kW_Hourly: float, Gas_Facility_kW_Hourly: float, Heating_Gas_kW_Hourly: float, InteriorEquipments_Gas_kW_Hourly: float, WaterHeater_WaterSystems_Gas_kW_Hourly: float, filename: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c79a89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:======>                                                    (1 + 8) / 9]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1962240"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee79d6d4",
   "metadata": {},
   "source": [
    "### Get column-wise null records for the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf998fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------+--------------------------+-----------------------------+-----------------------------+------------------------------------+----------------------------------------+----------------------+---------------------+--------------------------------+--------------------------------------+--------+\n",
      "|DTime|Electricity_Facility_kW_Hourly|Fans_Electricity_kW_Hourly|Cooling_Electricity_kW_Hourly|Heating_Electricity_kW_Hourly|InteriorLights_Electricity_kW_Hourly|InteriorEquipments_Electricity_kW_Hourly|Gas_Facility_kW_Hourly|Heating_Gas_kW_Hourly|InteriorEquipments_Gas_kW_Hourly|WaterHeater_WaterSystems_Gas_kW_Hourly|filename|\n",
      "+-----+------------------------------+--------------------------+-----------------------------+-----------------------------+------------------------------------+----------------------------------------+----------------------+---------------------+--------------------------------+--------------------------------------+--------+\n",
      "|    0|                             0|                    479438|                       739920|                      1841254|                                   0|                                       0|                269935|              1162371|                          449680|                                858480|       0|\n",
      "+-----+------------------------------+--------------------------+-----------------------------+-----------------------------+------------------------------------+----------------------------------------+----------------------+---------------------+--------------------------------+--------------------------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan,when,count\n",
    "df2=newDF.select([count(when(col(c).contains('None')|\\\n",
    "                             col(c).contains('NULL')|\\\n",
    "                             (col(c)=='')|\\\n",
    "                             col(c).isNull()|\\\n",
    "                             (col(c)==0)|\\\n",
    "                             isnan(c),c\n",
    "                            )).alias(c) \n",
    "                  for c in newDF.columns])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09c55e1",
   "metadata": {},
   "source": [
    "### Partition of the resultant data frame by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e876b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making month column\n",
    "df_month=newDF.withColumn(\"Month\",substring('DTime',1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ab6360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12:=========================>                                (4 + 5) / 9]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|partition_id| count|\n",
      "+------------+------+\n",
      "|           1|219000|\n",
      "|           6|227760|\n",
      "|           3|227760|\n",
      "|           5|227760|\n",
      "|           4|227760|\n",
      "|           8|148920|\n",
      "|           7|236520|\n",
      "|           2|227760|\n",
      "|           0|219000|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql.functions import spark_partition_id\n",
    "df_month.select(spark_partition_id().alias(\"partition_id\")).groupBy(\"partition_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "707dcb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|partition_id| count|\n",
      "+------------+------+\n",
      "|           1|196224|\n",
      "|           6|196224|\n",
      "|           3|196224|\n",
      "|           5|196224|\n",
      "|           9|196224|\n",
      "|           4|196224|\n",
      "|           8|196224|\n",
      "|           7|196224|\n",
      "|           2|196224|\n",
      "|           0|196224|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_month.repartition(10).select(spark_partition_id().alias(\"partition_id\")).groupBy(\"partition_id\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce8c3c",
   "metadata": {},
   "source": [
    "### Get the number of rows from each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bd6e718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_month.write.partitionBy('month').format('csv').mode('overwrite').option(\"header\",True).save(\"hdfs://127.0.0.1:9000/user/labuser/bdpl/electricity_data/monthly_consumption_partitions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74a2abc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_SUCCESS',\n",
       " 'month= 01',\n",
       " 'month= 02',\n",
       " 'month= 03',\n",
       " 'month= 04',\n",
       " 'month= 05',\n",
       " 'month= 06',\n",
       " 'month= 07',\n",
       " 'month= 08',\n",
       " 'month= 09',\n",
       " 'month= 10',\n",
       " 'month= 11',\n",
       " 'month= 12']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='hdfs://127.0.0.1:9000/user/labuser/bdpl/electricity_data/monthly_consumption_partitions/'\n",
    "fs=spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "list_status=fs.listStatus(spark._jvm.org.apache.hadoop.fs.Path(path))\n",
    "partitioned_files=[file.getPath().getName() for file in list_status]\n",
    "partitioned_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdefe11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month= 01 num_rows:166656\n",
      "month= 02 num_rows:150528\n",
      "month= 03 num_rows:166656\n",
      "month= 04 num_rows:161280\n",
      "month= 05 num_rows:166656\n",
      "month= 06 num_rows:161280\n",
      "month= 07 num_rows:166656\n",
      "month= 08 num_rows:166656\n",
      "month= 09 num_rows:161280\n",
      "month= 10 num_rows:166656\n",
      "month= 11 num_rows:161280\n",
      "month= 12 num_rows:166656\n"
     ]
    }
   ],
   "source": [
    "for file in partitioned_files[1:]:\n",
    "    path='hdfs://127.0.0.1:9000/user/labuser/bdpl/electricity_data/monthly_consumption_partitions/'+file\n",
    "    df=spark.read.csv(path,header=True)\n",
    "    print(file,'num_rows:'+str(df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e863c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
